{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STA 141B Homework 1\n",
    "===========\n",
    "- Fall 2021\n",
    "- Do not distribute\n",
    "\n",
    "You will be graded according to your ability to follow the instructions, maintain organized code, with docstrings on all defs.  You should focus on memory and time complexity, and do not read in more data than you need to.  Throughout this assignment you should be acting iteratively on the data and never read it all into RAM.  You can find the data in the following fastq file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@SRR6781412_BALB-c_mTEChi_1_4.1 1 length=160\r\n",
      "NCATCCTCCTCCTCTGAAAATTCCTCCACTTCTCGTCCTTCCTCAGGGATTTCCTGACCTGCCATTCGCAGCATCATGGCAAAAACATGAAGGAGCTGACTCCTCTTCAAGCCATGATGCTGCGAATGGCAGGTCAGGAAATCCCTGAGGAAGGACGAGA\r\n",
      "+SRR6781412_BALB-c_mTEChi_1_4.1 1 length=160\r\n",
      "#AAAAEEEEEEEEAEEEEEEEE6EEEEEEEEAEEEEEEEEEEEEEEAEEEEEEEEEEEEAEEEEEEEAEEAA/EE<EE6/AAAAAEEEEEAEAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAEEEEEEEEEAEEEAEEEAEEEEEEEEEEEAEEEE\r\n",
      "@SRR6781412_BALB-c_mTEChi_1_4.2 2 length=160\r\n",
      "NATCTTGTACCACTCCTACTTCGCCGTCGTCTTCTCTCTCTGCTTGCACTCCGAGAGCGTCTGGCTGTGCTGTAGCTTTTAGTAGAAGGAGATCCAAAAGTCCAAGACGGAGACGATCTCATTCCCGAGAGAGGGGTAGAAGGTCAAGGAGCACATCCAA\r\n",
      "+SRR6781412_BALB-c_mTEChi_1_4.2 2 length=160\r\n",
      "#AAAAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE/EAAEE/<EAA/EEEEEEE/EAEAEAEE<<E/E//E//E</AEEAAAAAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAEEEEEEEEEEEEEEEEEE<EEE\r\n",
      "@SRR6781412_BALB-c_mTEChi_1_4.3 3 length=160\r\n",
      "NTCCGGGCTCGGGACATTTGTGATTTCCTGAAGGATGGGCTGTCTGCTGACCTGTCCAAGGATTGGCAGCTTCCTGACAAGAACAGTCTAAGCTAGATCCCCTCAGCAGTGCCGAAAATTCCTTGTCAGGAAGCTGCCAATCCTTTGACAGGTCAGCAGA\r\n"
     ]
    }
   ],
   "source": [
    "!head ../data/dummy.fastq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fastq file is a way of encoding short genomic reads from high throughput sequencing technology, such as Illumina next generation sequencers.  It consists of\n",
    "\n",
    "1. A sequence identifier which for this sequencer starts with an @, then followed by a long name, and a length tag.\n",
    "2. The sequence (the base calls; A, C, T, G and N), N stands for not able to read, due to insufficient quality.\n",
    "3. A separator, which is simply a plus (+) sign, perhaps followed by the identifier.\n",
    "4. The base call quality scores. These are Phred +33 encoded, using ASCII characters to represent the numerical quality scores (more later).\n",
    "\n",
    "Each problem is worth equal number of points.  Modify all appropriate files in the directory structure (you should not need to add any new files).  Write up what you did below with additional cells in between the exercise cells, which you should leave in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 1__ Throughout this homework you should never read the full data into RAM.  You should be able to get practice only reading the data in sequence and not reading it into memory and manipulating it that way.  Do the following in code cells between Exercise 1 and 2.\n",
    "\n",
    "1. Write some code cells that counts the number of lines in the file without loading the file in memory.\n",
    "2. Each new read begins with a sequence identifier that begins with \"@\", write a short script that counts the number of sequences.\n",
    "3. Write a def which replaces all \"T\"s to \"U\" (transcript DNA to RNA) in a sequence.  Test it on an example sequence of your choice.\n",
    "4. Write a script that looks for any anomalous reads or junk in the data that doesn't follow the basic structure above.  Clean the data and document what you did below, add the script you used to find the anomalous lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer to 1.4** I will begin by writing a script that checks that for every 4 lines the first line starts with @ and the third starts with +.  I use `assert` to throw an error if this does not hold and print the offending line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@SRR6781412_BALB-c_mTEChi_1_4.1 1 length=160\n",
      "\n",
      "NCATCCTCCTCCTCTGAAAATTCCTCCACTTCTCGTCCTTCCTCAGGGATTTCCTGACCTGCCATTCGCAGCATCATGGCAAAAACATGAAGGAGCTGACTCCTCTTCAAGCCATGATGCTGCGAATGGCAGGTCAGGAAATCCCTGAGGAAGGACGAGA\n",
      "\n",
      "+SRR6781412_BALB-c_mTEChi_1_4.1 1 length=160\n",
      "\n",
      "#AAAAEEEEEEEEAEEEEEEEE6EEEEEEEEAEEEEEEEEEEEEEEAEEEEEEEEEEEEAEEEEEEEAEEAA/EE<EE6/AAAAAEEEEEAEAEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEAEEEEEEEEEAEEEAEEEAEEEEEEEEEEEAEEEE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('../data/dummy.fastq','r') as reader:\n",
    "    for i in range(4):\n",
    "        print(reader.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": ">>>>>>>>>>>>>>>>>>>>>HELLO THERE<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n\n@SRR6781412_BALB-c_mTEChi_1_4.11309 11309 length=160\n\nCCAGTCGGAAACGGCGCTGCTGTCAATGGCCCAATTATCTGAAACCTTTTCATCAGTTACCAGTTTCCTGAATACTGCTTGCCGAAACATGGCAGAGGTTGGGTCCAAGTCAGTGCTGTTCGTGTGTCTCGGTAACATTTGCCGGTCACCCATTGCAGAA\n\n+SRR6781412_BALB-c_mTEChi_1_4.11309 11309 length=160\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b9da8d7fb22a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"@\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"+\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: >>>>>>>>>>>>>>>>>>>>>HELLO THERE<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n\n@SRR6781412_BALB-c_mTEChi_1_4.11309 11309 length=160\n\nCCAGTCGGAAACGGCGCTGCTGTCAATGGCCCAATTATCTGAAACCTTTTCATCAGTTACCAGTTTCCTGAATACTGCTTGCCGAAACATGGCAGAGGTTGGGTCCAAGTCAGTGCTGTTCGTGTGTCTCGGTAACATTTGCCGGTCACCCATTGCAGAA\n\n+SRR6781412_BALB-c_mTEChi_1_4.11309 11309 length=160\n"
     ]
    }
   ],
   "source": [
    "with open('../data/dummy.fastq','r') as reader:\n",
    "    while reader:\n",
    "        lines = [reader.readline() for i in range(4)]\n",
    "        assert lines[0][0] == \"@\" and lines[2][0] == \"+\", \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like there is a line that starts with >>>> that should not be there.  I remove it using bash commands, and save it in `dummy_cleaned.fastq`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": ">>>>>>>>>>>>>>>>>>>>>>>>>>WHY ME??<<<<<<<<<<<<<<<<<<<<<<<<<<\n\n@SRR6781412_BALB-c_mTEChi_1_4.20085 20085 length=160\n\nGTGGGGGTGAATTCAGTGTGAGCCAGGATATAGAAAGACCAGTCCTTGCTGAAGGACATATCTGACATCTCTACTTTAGGTACTGAACTGCTACGTAACACAGTTCCACCCGCCTCACATTGAAATCCAAATGCTGAAGAACGGGAAAAAAATTCCTAAA\n\n+SRR6781412_BALB-c_mTEChi_1_4.20085 20085 length=160\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-7b7b11221d6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"@\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"+\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: >>>>>>>>>>>>>>>>>>>>>>>>>>WHY ME??<<<<<<<<<<<<<<<<<<<<<<<<<<\n\n@SRR6781412_BALB-c_mTEChi_1_4.20085 20085 length=160\n\nGTGGGGGTGAATTCAGTGTGAGCCAGGATATAGAAAGACCAGTCCTTGCTGAAGGACATATCTGACATCTCTACTTTAGGTACTGAACTGCTACGTAACACAGTTCCACCCGCCTCACATTGAAATCCAAATGCTGAAGAACGGGAAAAAAATTCCTAAA\n\n+SRR6781412_BALB-c_mTEChi_1_4.20085 20085 length=160\n"
     ]
    }
   ],
   "source": [
    "with open('../data/dummy_cleaned.fastq','r') as reader:\n",
    "    while reader:\n",
    "        lines = [reader.readline() for i in range(4)]\n",
    "        assert lines[0][0] == \"@\" and lines[2][0] == \"+\", \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that there is another line that should not be there, I remove it also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-01ad4607140f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"@\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"+\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "with open('../data/dummy_cleaned2.fastq','r') as reader:\n",
    "    while reader:\n",
    "        lines = [reader.readline() for i in range(4)]\n",
    "        assert lines[0][0] == \"@\" and lines[2][0] == \"+\", \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The assertion is never thrown and it looks like we reach the end of the file.  I saved the cleaned data in `dummy_cleaned2.fastq`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 2__ Quality scores are encoded as ASCII characters with the lowest being \"!\" (which has ASCII code of 33) and the highest being \"I\" (which has ASCII code of 73).  Create a def which takes in the quality character and returns a number between 0 and 1 with 0 the lowest and 1 the highest.  The function should be a linear function of the ASCII code.  (Hint: check out the `chr` and `ord` built-in functions.)  Test it out on an arbitrary sequence from the data (you can just read in the first sequence if you like).  Add this to **def quality_score** in code/fastq_reader.py, as usual add a docstring describing the function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More hints, find numbers a,b such that\n",
    "```\n",
    "(ord('!') - a)/b == 0\n",
    "(ord('I') - a)/b == 1\n",
    "```\n",
    "This is your mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ord(\"/\") - a)/b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord(\"#\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 3__ Write a python script that iterates through the file, and for each sequence, calculates the average quality score (as defined above).  Have the script print the sequence id for the sequence with the highest average quality, and for the sequence with the lowest average quality.  Modify code/seq_quality.py and save it over the given template.  There may be multiple sequences with the highest/lowest average quality scores, so you should just output the first sequence ID such that the average quality score is the maximum/minimum.  You should just print the sequence IDs since that is easier to identify than the sequences themselves, and the sequence ID does not need to be parsed and you can just print out the entire line starting with \"@\" containing the sequence ID."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 4__ Write a python script that iterates through the file, and calculates the average quality of each of the 5 bases (A,T,G,C,N).  Print these to the screen as well, modify code/base_quality.py."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 5__ In a sequence of tokens (such as characters in this case) an n-gram is a sequence of n tokens that follow one another in the sequence.  Fill **def ngram_freq** in code/fastq_reader.py which should take a sequence string and n as an input and output a dictionary.  This dictionary should have keys that are n-grams and values which are the frequency of that n-gram in the sequence (the percentage of all n-gram instances in the sequence which match a specific n-gram).  As an example, the 2-gram frequencies of the sequence \"TGTGCT\" are\n",
    "\n",
    "\"TG\": 2/5, \"GT\" : 1/5, \"GC\" : 1/5, \"CT\" : 1/5.\n",
    "\n",
    "Hint: it may be useful to use the Counter class in the collections package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some examples,\n",
    "```\n",
    ">>> ngram_freq(\"TGCTTGC\", n=2)\n",
    "\n",
    "{'TG': 0.3333333333333333,\n",
    " 'GC': 0.3333333333333333,\n",
    " 'CT': 0.16666666666666666,\n",
    " 'TT': 0.16666666666666666}\n",
    " \n",
    ">>> ngram_freq(\"CTGAATG\", n=2)\n",
    "\n",
    "{'CT': 0.16666666666666666,\n",
    " 'TG': 0.3333333333333333,\n",
    " 'GA': 0.16666666666666666,\n",
    " 'AA': 0.16666666666666666,\n",
    " 'AT': 0.16666666666666666}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 6__ Fill in **def ngram_sim** which takes two sequences and outputs the following notion of similarity:\n",
    "$$\\sum_g \\sqrt{f(g) h(g)}$$\n",
    "where g are all n-grams in both sequences, f(g) is the frequency of g in the first sequence and h(g) is the frequency in the second.  Test this on an arbitrary pair of sequences.\n",
    "\n",
    "There are likely to be n-grams that do not occur in both sequences (but may occur in one of them).  You can start by finding only the set of n-grams that occurs in both sequences.  Then you can compute $\\sqrt{f(g) h(g)}$ for only those n-grams that are in both and sum them up.  Note that these n-grams are the intersection of the n-grams in the two sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example based on the test cases above,\n",
    "```\n",
    ">>> ngf1 = ngram_freq(\"TGCTTGC\", n=2)\n",
    ">>> ngf2 = ngram_freq(\"CTGAATG\", n=2)\n",
    ">>> ngram_sim(ngf1, ngf2)\n",
    "\n",
    "0.5\n",
    "```\n",
    "We can see this because the following is true.\n",
    "```\n",
    ">>> (1/3 * 1/3)**0.5 + (1/6 * 1/6)**0.5\n",
    "\n",
    "0.5\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 7__ Use regular expression and the re package to do the following.  Write a new script in code/find_re.py that uses this iterator to read through the file and print to screen the sequence identifiers with the following characteristics:\n",
    "1. The longest continuous sequence of repeated \"TCC\"s.  For example \"AGTCCTCCTCCAG\" has 3 repeats.\n",
    "2. The most matches to G_G where _ is any base.\n",
    "3. The longest sequence of any one base, as in \"GTAAAAAAAGTA\" has a 7 As in a row."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the documentation for findall...\n",
    "\n",
    "re.findall(pattern, string, flags=0)\n",
    "\n",
    "Return all non-overlapping matches of pattern in string, as a list of strings. The string is scanned left-to-right, and matches are returned in the order found. If one or more groups are present in the pattern, return a list of groups; this will be a list of tuples if the pattern has more than one group. Empty matches are included in the result.\n",
    "\n",
    "We can see an example below, where we are looking for repeats of \"ba\" in a string,\n",
    "\n",
    "```\n",
    ">>> re.findall('((ba)+)','abaaababaaaba')\n",
    "\n",
    "[('ba', 'ba'), ('baba', 'ba'), ('ba', 'ba')]\n",
    "```\n",
    "\n",
    "Each element of the list is a match, and the tuples inside correspond to the groups within the pattern.  The parentheses () denote a group and so because there are two sets you obtain two groups for each match.  The first is the outer parentheses, which is the desired match."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
